# ğŸš€ QUICK START GUIDE

## Bihar Board Books Scraper - Complete Solution

### ğŸ“¦ What You Got

âœ… **Complete scraper** to fetch all Bihar Board books (Classes 1-12)  
âœ… **PDF downloader** with organized folder structure  
âœ… **FastAPI integration** ready to use  
âœ… **Data management** system  
âœ… **Easy-to-use** command-line tool  

---

## âš¡ Quick Start (3 Steps)

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2: Scrape Books
```bash
python run_scraper.py --scrape
```

This creates `bihar_board_books.json` with all book metadata.

### Step 3: Download PDFs (Optional)
```bash
python run_scraper.py --download
```

This downloads all PDFs to `bihar_board_books/` folder.

---

## ğŸ“ Files Included

| File | Purpose |
|------|---------|
| `bihar_books_scraper.py` | Main scraper - fetches book metadata |
| `pdf_downloader.py` | Downloads PDFs in organized folders |
| `books_data_manager.py` | Data models & API helpers |
| `updated_books_route.py` | FastAPI routes (replace your existing) |
| `run_scraper.py` | **Easy command-line tool** â­ |
| `requirements.txt` | Python dependencies |
| `README.md` | Complete documentation |

---

## ğŸ¯ Common Usage

### Scrape Specific Classes
```bash
# Only scrape Classes 1, 2, 3
python run_scraper.py --scrape --classes 1 2 3
```

### Download Limited Books (Testing)
```bash
# Download only first 5 books
python run_scraper.py --download --limit 5
```

### Full Workflow
```bash
# Scrape and download in one command
python run_scraper.py --scrape --download
```

### View Statistics
```bash
python run_scraper.py --stats
```

---

## ğŸ”§ FastAPI Integration

### Replace Your Books Route

**Current file:** `app/routes/books_route.py`

**Replace with:** `updated_books_route.py`

```python
# In your main app
from updated_books_route import router as books_router

app.include_router(books_router)
```

### New API Endpoints Available

```
GET  /books/list              # List all books (with filters)
GET  /books/statistics         # Get stats
GET  /books/classes            # List all classes
GET  /books/subjects           # List all subjects
GET  /books/{book_id}          # Get book details
GET  /books/search/?q=math     # Search books
POST /books/scrape/update      # Update database
POST /books/download/{book_id} # Download book PDFs
```

---

## ğŸ“Š Expected Output

### After Scraping
```
bihar_board_books.json           â† Complete database
bihar_board_books_summary.json   â† Statistics
```

### After Downloading
```
bihar_board_books/
â”œâ”€â”€ Class_I/
â”‚   â”œâ”€â”€ English/
â”‚   â”‚   â””â”€â”€ Blossom/
â”‚   â”‚       â”œâ”€â”€ chapter_1.pdf
â”‚   â”‚       â”œâ”€â”€ chapter_2.pdf
â”‚   â”‚       â””â”€â”€ metadata.json
â”‚   â””â”€â”€ Mathematics/
â”œâ”€â”€ Class_II/
â””â”€â”€ ...
```

---

## ğŸ’¡ Pro Tips

### 1. Start Small
Test with a few classes first:
```bash
python run_scraper.py --scrape --classes 1
python run_scraper.py --download --limit 3
```

### 2. Check Progress
View statistics after scraping:
```bash
python run_scraper.py --stats
```

### 3. Resume Downloads
Already downloaded PDFs are skipped automatically.

### 4. Check Dependencies
```bash
python run_scraper.py --check
```

---

## ğŸ› ï¸ Troubleshooting

### Problem: "Module not found"
**Solution:**
```bash
pip install -r requirements.txt
```

### Problem: "Books data not found"
**Solution:** Run scraper first:
```bash
python run_scraper.py --scrape
```

### Problem: Download is slow
**Solution:** This is normal. PDFs are large. Be patient! â˜•

### Problem: Some PDFs fail
**Solution:** Website might be temporarily down. Check logs and retry.

---

## ğŸ“ˆ What to Expect

### Scraping Time
- **Classes 1-12**: ~10-20 minutes
- **Single class**: ~1-2 minutes

### Download Time
- **All books**: Several hours (depends on internet)
- **Single class**: ~30-60 minutes

### Storage Space
- **JSON data**: ~5-10 MB
- **All PDFs**: ~5-10 GB (estimated)

---

## ğŸ“ Example Workflow

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Test with Class 1 only
python run_scraper.py --scrape --classes 1

# 3. Check what you got
python run_scraper.py --stats

# 4. Download Class 1 books
python run_scraper.py --download

# 5. If all good, scrape everything
python run_scraper.py --scrape

# 6. Download everything (run overnight)
nohup python run_scraper.py --download &
```

---

## ğŸ“š Data Structure

### Books JSON Format
Each book contains:
- Class name (e.g., "Class I")
- Subject (e.g., "Mathematics")
- Book title
- URL to book page
- Chapters (if available)
- All PDF links
- Total PDF count

### API Response Format
```json
{
  "id": "class_i_mathematics_ganit",
  "class_num": 1,
  "subject": "Mathematics",
  "title": "à¤—à¤£à¤¿à¤¤ (Ganit)",
  "total_pdfs": 15,
  "chapters": [...]
}
```

---

## ğŸš¨ Important Notes

1. **Be Respectful**: The scraper includes delays. Don't modify them.
2. **Internet Required**: Both scraping and downloading need stable internet.
3. **Storage Space**: Ensure you have enough disk space (~10 GB).
4. **Time Required**: Full download takes hours. Use `nohup` to run in background.
5. **Legal**: This is for educational purposes. Respect website's terms of service.

---

## ğŸ†˜ Need Help?

1. **Check Logs**: All operations are logged
2. **Read README.md**: Complete documentation
3. **Test Small**: Start with 1-2 classes
4. **Check Website**: Ensure https://bepclots.bihar.gov.in/ is accessible

---

## âœ¨ Next Steps

After successful scraping and downloading:

1. âœ… Integrate `updated_books_route.py` into your FastAPI app
2. âœ… Test the API endpoints
3. âœ… Build your frontend to consume the API
4. âœ… Schedule regular updates (weekly/monthly)

---

## ğŸ‰ You're All Set!

Start with:
```bash
python run_scraper.py --scrape --classes 1
```

Good luck! ğŸš€
